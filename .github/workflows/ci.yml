name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION_MATRIX: "3.11,3.12"

jobs:
  # Job 1: Lint and Format Check
  lint-and-format:
    name: Lint & Format Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install --system -e ".[dev]"

      - name: Run ruff linting
        run: |
          ruff check . --output-format=github

      - name: Check code formatting
        run: |
          ruff format --check .

  # Job 2: Security Scan
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install --system -e ".[dev]"

      - name: Run safety check
        run: |
          pip install safety
          safety check

      - name: Run bandit security scan
        run: |
          pip install bandit
          bandit -r python/ modelcontextprotocol/ -f json -o bandit-results.json || true

      - name: Upload security scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-scan-results
          path: bandit-results.json

  # Job 3: Unit Tests Matrix
  unit-tests:
    name: Unit Tests
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.11", "3.12"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ matrix.python-version }}-pip-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-py${{ matrix.python-version }}-pip-

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install --system -e ".[dev]"

      - name: Create test environment file
        run: |
          cp env.example .env
          echo "JUSTIFI_ACCOUNT_ID=test_account" >> .env
          echo "JUSTIFI_API_KEY=test_key" >> .env
          echo "JUSTIFI_ENVIRONMENT=test" >> .env

      - name: Run unit tests with coverage
        run: |
          pytest tests/ -v --cov=python --cov=modelcontextprotocol --cov-report=xml --cov-report=html --cov-report=term-missing

      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v4
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12'
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: |
            coverage.xml
            htmlcov/
            .coverage

  # Job 4: Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [lint-and-format, unit-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install --system -e ".[dev]"

      - name: Create test environment file
        run: |
          cp env.example .env
          echo "JUSTIFI_ACCOUNT_ID=test_account" >> .env
          echo "JUSTIFI_API_KEY=test_key" >> .env
          echo "JUSTIFI_ENVIRONMENT=test" >> .env

      - name: Test MCP server initialization
        run: |
          timeout 10s python main.py || [ $? -eq 124 ]

      - name: Run integration tests (if any)
        run: |
          # Run any integration tests that might exist
          if [ -d "tests/integration" ]; then
            pytest tests/integration/ -v
          else
            echo "No integration tests found, skipping..."
          fi

  # Job 5: Docker Build Test
  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    needs: [lint-and-format]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create test environment file
        run: |
          cp env.example .env
          echo "JUSTIFI_ACCOUNT_ID=test_account" >> .env
          echo "JUSTIFI_API_KEY=test_key" >> .env
          echo "JUSTIFI_ENVIRONMENT=test" >> .env

      - name: Build development Docker image
        run: |
          docker build --target development -t justifi-mcp-server:dev .

      - name: Build production Docker image
        run: |
          docker build --target production -t justifi-mcp-server:prod .

      - name: Test development container
        run: |
          docker run --rm --env-file .env justifi-mcp-server:dev python -c "import python.core; print('Development container works!')"

      - name: Test production container (basic smoke test)
        run: |
          # Run a basic smoke test - start the server and kill it after 5 seconds
          timeout 5s docker run --rm --env-file .env justifi-mcp-server:prod || [ $? -eq 124 ]

  # Job 6: API Drift Detection
  api-drift-check:
    name: API Drift Check
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install --system -e ".[dev,api]"

      - name: Create test environment file
        run: |
          cp env.example .env
          echo "JUSTIFI_ACCOUNT_ID=test_account" >> .env
          echo "JUSTIFI_API_KEY=test_key" >> .env
          echo "JUSTIFI_ENVIRONMENT=test" >> .env

      - name: Run API drift check
        run: |
          python scripts/ci-drift-check.py || echo "API drift check completed with warnings"

  # Job 7: Build Summary
  build-summary:
    name: Build Summary
    runs-on: ubuntu-latest
    needs: [lint-and-format, security-scan, unit-tests, integration-tests, docker-build, api-drift-check]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Generate build summary
        run: |
          echo "## üöÄ CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Job Status:" >> $GITHUB_STEP_SUMMARY
          echo "- **Lint & Format**: ${{ needs.lint-and-format.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Security Scan**: ${{ needs.security-scan.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Unit Tests**: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Integration Tests**: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Docker Build**: ${{ needs.docker-build.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **API Drift Check**: ${{ needs.api-drift-check.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìä Test Coverage" >> $GITHUB_STEP_SUMMARY
          echo "Coverage reports are available in the artifacts." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üîß Next Steps" >> $GITHUB_STEP_SUMMARY
          if [ "${{ needs.lint-and-format.result }}" = "failure" ]; then
            echo "- Fix linting and formatting issues" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "${{ needs.unit-tests.result }}" = "failure" ]; then
            echo "- Fix failing unit tests" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "${{ needs.docker-build.result }}" = "failure" ]; then
            echo "- Fix Docker build issues" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "_Generated by JustiFi MCP Server CI/CD Pipeline_" >> $GITHUB_STEP_SUMMARY

      - name: Check overall build status
        run: |
          if [ "${{ needs.lint-and-format.result }}" = "failure" ] || [ "${{ needs.unit-tests.result }}" = "failure" ] || [ "${{ needs.docker-build.result }}" = "failure" ]; then
            echo "‚ùå Build failed - check the job logs for details"
            exit 1
          else
            echo "‚úÖ Build completed successfully"
          fi